{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import caer\n",
    "import canaro\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as imgdatgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to adjust the constants to suit your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (80,80)\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 10\n",
    "channels = 1\n",
    "dataset_path = r\"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a frequency Dictionary to see how many images are there in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = {}\n",
    "for folder in os.listdir(dataset_path):\n",
    "    chars[folder] = len(os.listdir(os.path.join(dataset_path, folder)))\n",
    "chars_list= caer.sort_dict(chars , descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are more a large number of categories, You can choose to train a small amount of them with.\n",
    "<br>The entire code is assuming you train only the top 10 categories with highest number of samples.\n",
    "<br>You can choose to skip it and alter the code to suit you needs.\n",
    "<br>You can replace the variable <span style='color: orange;'>top</span> with variable <span style='color: orange;'>chars_list</span>.\n",
    "<br>if you wish to train all the images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = [i[0] for i in chars_list[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a training set from the data of Top 10 categories\n",
    "<br>If there are more categories, It will take more time depending upon the processing power of your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = caer.preprocess_from_dir(dataset_path,top, channels = channels,IMG_SIZE=IMG_SIZE,isShuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet , label = caer.sep_train(training_set,IMG_SIZE=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize feature set and change labels into categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = caer.normalize(featureSet)\n",
    "label = to_categorical(label,len(top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data into training set and validation set(testing set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_val , y_train , y_val = caer.train_val_split(featureSet,label,val_ratio=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the training_set , featureSet and labels datas are useless at this point since we created a training and testing dataset and you can garbage collect them whenever you want after this point to reduce memory useag using the command\n",
    "\n",
    "<br> <span style='color: red;'>del</span> training_set\n",
    "<br> <span style='color: red;'>del</span> featureSet\n",
    "<br> <span style='color: red;'>del</span> label\n",
    "<br> gc.<span style='color: green;'>collect()</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = canaro.generators.imageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: yellow;'> canaro.generators.imageDataGenerator()</span>\n",
    "<br> is just imageDataGenerator of Tensorflow with certain arguements already passed\n",
    "<br>please feel free to modify the dataget variable with ImageDataGenerator() and give your own arguments to match your needs\n",
    "<br>You can change it bu doing\n",
    "<br><span style='color: orange;'>from tensorflow.keras.preprocessing.image import ImageDataGenerator as imgdatgen</span>\n",
    "<br>datagen = imgdatgen(<span style='color: orange;'>\"Your Arguments Here\"</span>)\n",
    "<br>Refer Next CodeBlock for modifying imgdatagen parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as imgdatgen\n",
    "def imageDataGenerator():\n",
    "    datagen = imgdatgen(rotation_range=10, \n",
    "                           width_shift_range=.1,\n",
    "                           height_shift_range=.1,\n",
    "                           shear_range=.2,\n",
    "                           zoom_range=.2,\n",
    "                           horizontal_flip=True,\n",
    "                           fill_mode='nearest')\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flow Takes data & label arrays, generates batches of augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = datagen.flow(x_train,y_train,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important part, This is the neural Network consiting of different layers\n",
    "<br>Feel free to adjut data values as you see fit to match your usecase\n",
    "<br>This is the Abstracted model of canaro.models.createSimpsonsModel() , you can use that directly if you dont want to play around with neural layers and\n",
    "<br>Keras depreciated decay , change it to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(IMG_SIZE=(224,224), channels=1, output_dim=1, loss='binary_crossentropy', decay=None, learning_rate=None, momentum=None, nesterov=None):\n",
    "    if not isinstance(output_dim, int):\n",
    "        raise ValueError('[ERROR] Output dimensions need to be an integer')\n",
    "    if not isinstance(channels, int):\n",
    "        raise ValueError('[ERROR] Channels needs to be an integer')\n",
    "        \n",
    "    w, h = IMG_SIZE[:2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(w, h, channels)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu')) \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(w, h,channels)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu')) \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    optimizer = SGD(learning_rate=learning_rate, decay=decay, momentum=momentum, nesterov=nesterov)\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(IMG_SIZE=IMG_SIZE, channels = channels, \n",
    "                                        output_dim=len(top), \n",
    "                                        loss = 'binary_crossentropy',\n",
    "                                        decay=1e-6, \n",
    "                                        learning_rate=0.001,\n",
    "                                        momentum = 0.9,\n",
    "                                        nesterov =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedule Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [LearningRateScheduler(canaro.lr_schedule)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model, increase/Decrease Epochs as you see fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = model.fit(train_gen,\n",
    "                    steps_per_epoch = len(train_gen) // BATCH_SIZE,\n",
    "                    epochs = 20,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    validation_steps = len(y_val)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing part, Ignore if you dont want to test individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r\"Path of the image\"\n",
    "img = cv.imread(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting images to suit the models input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(img):\n",
    "    \n",
    "    img = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    img = cv.resize(img,IMG_SIZE)\n",
    "    img = caer.reshape(img,IMG_SIZE,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(conv(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top[np.argmax(prediction[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test every image in a given category of images and see how many are guessed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {}\n",
    "faults = []\n",
    "Dir = \"folder Path of a category of images you used in training\"\n",
    "for i in os.listdir(Dir):\n",
    "    try:\n",
    "        imgs = Dir + i\n",
    "        img = cv.imread(imgs)\n",
    "        prediction = model.predict(conv(img))\n",
    "        if top[np.argmax(prediction[0])] in dicts:\n",
    "            dicts[top[np.argmax(prediction[0])]] += 1\n",
    "        else:\n",
    "            dicts[top[np.argmax(prediction[0])]] = 1\n",
    "    except:\n",
    "        faults.append(i)\n",
    "        \n",
    "        continue\n",
    "print(dicts)\n",
    "print(faults)\n",
    "print(len(faults))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
